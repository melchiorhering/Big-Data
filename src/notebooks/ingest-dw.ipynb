{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest Data Warehouse\n",
    "\n",
    "### Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from typing import Optional\n",
    "from lib.duckdbcontext import DuckDBContext\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "import duckdb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n",
      "0.9.2\n"
     ]
    }
   ],
   "source": [
    "print(pyspark.__version__)\n",
    "print(duckdb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb_database = \"../orchestration/db/bigdata.duckdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_name(file_name: str) -> str:\n",
    "    return file_name.rsplit(\".\", 2)[0]\n",
    "\n",
    "\n",
    "def create_url(endpoint: str) -> str:\n",
    "    \"\"\"\n",
    "    Create Url\n",
    "\n",
    "    :param str endpoint: download endpoint\n",
    "    :return str: full url\n",
    "    \"\"\"\n",
    "    return f\"https://datasets.imdbws.com/{endpoint}\"\n",
    "\n",
    "\n",
    "def download_file(url, filename):\n",
    "    print(f\"Downloading file: {filename}\")\n",
    "\n",
    "    response = urllib.request.urlopen(url)\n",
    "\n",
    "    # Get the total file size\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Create a tqdm progress bar\n",
    "    progress = tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=filename)\n",
    "\n",
    "    chunk_size = 1024  # you can change this to larger if you want\n",
    "\n",
    "    with open(filename, \"wb\") as f:\n",
    "        while True:\n",
    "            chunk = response.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            f.write(chunk)\n",
    "            progress.update(len(chunk))\n",
    "    progress.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Cluster Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Existing Spark Cluster\n",
    "# spark = (\n",
    "#     SparkSession.builder.master(\"spark://spark:7077\")\n",
    "#     .appName(\"Spark-ETL\")\n",
    "#     .config(\"spark.sql.debug.maxToStringFields\", 1000)\n",
    "#     .getOrCreate()\n",
    "# )\n",
    "\n",
    "# Connect to local Spark Sessions\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local\")\n",
    "    .appName(\"Spark-ETL\")\n",
    "    # .config(\"spark.sql.debug.maxToStringFields\", 1000)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add to Data Warehouse\n",
    "\n",
    "## Initial Data\n",
    "\n",
    "#### Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../../data/train-8.csv', '../../data/train-2.csv', '../../data/train-7.csv', '../../data/train-5.csv', '../../data/train-3.csv', '../../data/train-4.csv', '../../data/train-1.csv', '../../data/train-6.csv']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|   tconst|        primaryTitle|     originalTitle|         startYear|           endYear|    runtimeMinutes|          numVotes|\n",
      "+-------+---------+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|     7959|                7959|              3971|              7173|               786|              7946|              7169|\n",
      "|   mean|     NULL|   1231.388888888889|            1128.0|1997.9960964728843|1998.7633587786258|105.68713818273345| 29520.51081043381|\n",
      "| stddev|     NULL|   954.6947857755001|1038.0438333712118| 21.99534723241901|   21.895931761063| 25.39634772412447|114449.99384975343|\n",
      "|    min|tt0009369|\"Drágớn Báll Z: R...|     'A' gai wak 2|              1918|              1921|                45|            1001.0|\n",
      "|    max|tt9911196|             Ớútcást|        Üç Kagitçi|              2021|              2021|               551|         2503641.0|\n",
      "+-------+---------+--------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n",
      "+---------+--------------------+---------------+---------+-------+--------------+--------+-----+\n",
      "|   tconst|        primaryTitle|  originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|\n",
      "+---------+--------------------+---------------+---------+-------+--------------+--------+-----+\n",
      "|tt0014109|The Saga of Gösta...|           NULL|     1924|   NULL|           183|  1231.0| true|\n",
      "|tt0015064|      The Last Laugh|Der letzte Mann|     1924|   NULL|            77|    NULL| true|\n",
      "|tt0015841|        The Freshman|   The Freshman|     1925|   NULL|            77|  5374.0| true|\n",
      "|tt0017271|          By the Law|           NULL|     NULL|   1926|            80|  1057.0| true|\n",
      "|tt0018451|The Student Princ...|           NULL|     1927|   NULL|           106|  1459.0| true|\n",
      "+---------+--------------------+---------------+---------+-------+--------------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all CSV files that match the pattern\n",
    "csv_files = glob.glob(\"../../data/train-*.csv\")\n",
    "print(csv_files)\n",
    "\n",
    "# Load all CSV files in the data directory into a dataframe\n",
    "# Specify '\\\\N' as a null value\n",
    "# Ignore the header and infer the schema from data\n",
    "train_spark_df = (\n",
    "    spark.read.option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(\"../../data/train-*.csv\", nullValue=\"\\\\N\")\n",
    ")\n",
    "# Drop the first column\n",
    "train_spark_df = train_spark_df.drop(\"_c0\")\n",
    "train_spark_df.describe().show()\n",
    "# Print the dataframe\n",
    "train_spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>movie</th><th>director</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;tt0003740&quot;</td><td>&quot;nm0665163&quot;</td></tr><tr><td>&quot;tt0008663&quot;</td><td>&quot;nm0803705&quot;</td></tr><tr><td>&quot;tt0009369&quot;</td><td>&quot;nm0428059&quot;</td></tr><tr><td>&quot;tt0009369&quot;</td><td>&quot;nm0949648&quot;</td></tr><tr><td>&quot;tt0010307&quot;</td><td>&quot;nm0304098&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌───────────┬───────────┐\n",
       "│ movie     ┆ director  │\n",
       "│ ---       ┆ ---       │\n",
       "│ str       ┆ str       │\n",
       "╞═══════════╪═══════════╡\n",
       "│ tt0003740 ┆ nm0665163 │\n",
       "│ tt0008663 ┆ nm0803705 │\n",
       "│ tt0009369 ┆ nm0428059 │\n",
       "│ tt0009369 ┆ nm0949648 │\n",
       "│ tt0010307 ┆ nm0304098 │\n",
       "└───────────┴───────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Polars to retrieve the directing data\n",
    "# Load and parse the JSON file\n",
    "with open(\"../../data/directing.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "movies_polars_df = pl.from_dict(data[\"movie\"]).transpose().rename({\"column_0\": \"movie\"})\n",
    "directors_polars_df = (\n",
    "    pl.from_dict(data[\"director\"]).transpose().rename({\"column_0\": \"director\"})\n",
    ")\n",
    "directing_polars_df = pl.concat(\n",
    "    [\n",
    "        movies_polars_df,\n",
    "        directors_polars_df,\n",
    "    ],\n",
    "    how=\"horizontal\",\n",
    ")\n",
    "directing_polars_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|    movie|   writer|\n",
      "+---------+---------+\n",
      "|tt0003740|nm0195339|\n",
      "|tt0003740|nm0515385|\n",
      "|tt0003740|nm0665163|\n",
      "|tt0003740|nm0758215|\n",
      "|tt0008663|nm0406585|\n",
      "+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/writing.json\") as f:\n",
    "    data = json.load(f)\n",
    "writing_json = spark.sparkContext.parallelize(data)\n",
    "writing_spark_df = spark.read.json(writing_json)\n",
    "writing_spark_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load into DuckDB Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: imdb_train WITH 7959 ROWS!\n",
      "shape: (5, 8)\n",
      "┌───────────┬───────────────┬──────────────┬───────────┬─────────┬──────────────┬──────────┬───────┐\n",
      "│ tconst    ┆ primaryTitle  ┆ originalTitl ┆ startYear ┆ endYear ┆ runtimeMinut ┆ numVotes ┆ label │\n",
      "│ ---       ┆ ---           ┆ e            ┆ ---       ┆ ---     ┆ es           ┆ ---      ┆ ---   │\n",
      "│ str       ┆ str           ┆ ---          ┆ i32       ┆ i32     ┆ ---          ┆ f64      ┆ bool  │\n",
      "│           ┆               ┆ str          ┆           ┆         ┆ i32          ┆          ┆       │\n",
      "╞═══════════╪═══════════════╪══════════════╪═══════════╪═════════╪══════════════╪══════════╪═══════╡\n",
      "│ tt0014109 ┆ The Saga of   ┆ null         ┆ 1924      ┆ null    ┆ 183          ┆ 1231.0   ┆ true  │\n",
      "│           ┆ Gösta Berling ┆              ┆           ┆         ┆              ┆          ┆       │\n",
      "│ tt0015064 ┆ The Last      ┆ Der letzte   ┆ 1924      ┆ null    ┆ 77           ┆ null     ┆ true  │\n",
      "│           ┆ Laugh         ┆ Mann         ┆           ┆         ┆              ┆          ┆       │\n",
      "│ tt0015841 ┆ The Freshman  ┆ The Freshman ┆ 1925      ┆ null    ┆ 77           ┆ 5374.0   ┆ true  │\n",
      "│ tt0017271 ┆ By the Law    ┆ null         ┆ null      ┆ 1926    ┆ 80           ┆ 1057.0   ┆ true  │\n",
      "│ tt0018451 ┆ The Student   ┆ null         ┆ 1927      ┆ null    ┆ 106          ┆ 1459.0   ┆ true  │\n",
      "│           ┆ Prince in Old ┆              ┆           ┆         ┆              ┆          ┆       │\n",
      "│           ┆ Heidel…       ┆              ┆           ┆         ┆              ┆          ┆       │\n",
      "└───────────┴───────────────┴──────────────┴───────────┴─────────┴──────────────┴──────────┴───────┘\n",
      "CREATED TABLE: imdb_directors WITH 11162 ROWS!\n",
      "shape: (5, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ movie     ┆ director  │\n",
      "│ ---       ┆ ---       │\n",
      "│ str       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ tt0003740 ┆ nm0665163 │\n",
      "│ tt0008663 ┆ nm0803705 │\n",
      "│ tt0009369 ┆ nm0428059 │\n",
      "│ tt0009369 ┆ nm0949648 │\n",
      "│ tt0010307 ┆ nm0304098 │\n",
      "└───────────┴───────────┘\n",
      "CREATED TABLE: imdb_writing WITH 22428 ROWS!\n",
      "shape: (5, 2)\n",
      "┌───────────┬───────────┐\n",
      "│ movie     ┆ writer    │\n",
      "│ ---       ┆ ---       │\n",
      "│ str       ┆ str       │\n",
      "╞═══════════╪═══════════╡\n",
      "│ tt0003740 ┆ nm0195339 │\n",
      "│ tt0003740 ┆ nm0515385 │\n",
      "│ tt0003740 ┆ nm0665163 │\n",
      "│ tt0003740 ┆ nm0758215 │\n",
      "│ tt0008663 ┆ nm0406585 │\n",
      "└───────────┴───────────┘\n"
     ]
    }
   ],
   "source": [
    "# DuckDBContext to add pyspark tables to DuckDB\n",
    "with DuckDBContext(duckdb_database) as ctx:\n",
    "    ctx.save_to_duckdb(train_spark_df, \"imdb_train\")\n",
    "    ctx.show_n(\"imdb_train\", 5)\n",
    "\n",
    "    ctx.save_to_duckdb(directing_polars_df, \"imdb_directors\")\n",
    "    ctx.show_n(\"imdb_directors\", 5)\n",
    "\n",
    "    ctx.save_to_duckdb(writing_spark_df, \"imdb_writing\")\n",
    "    ctx.show_n(\"imdb_writing\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading\n",
    "\n",
    "Run this cell once, otherwise you'll keep downloading the same files over and over...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_imdb = [\n",
    "    \"name.basics.tsv.gz\",\n",
    "    \"title.akas.tsv.gz\",\n",
    "    \"title.basics.tsv.gz\",\n",
    "    \"title.crew.tsv.gz\",\n",
    "    # \"title.episode.tsv.gz\", # we have only movie data\n",
    "    \"title.principals.tsv.gz\",\n",
    "    \"title.ratings.tsv.gz\",\n",
    "]\n",
    "\n",
    "# RUN THIS ONCE!\n",
    "# # Download the files\n",
    "# for ds in extra_imdb:\n",
    "#     # Create an instance of the IMDB class with the desired endpoint\n",
    "#     download_url = create_url(ds)\n",
    "\n",
    "#     filepath = f\"../../data/extra/{ds}\"  # Local fp\n",
    "#     # Use the function to download the file\n",
    "#     download_file(download_url, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading with Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0053137,tt00723...|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0038355,tt00373...|\n",
      "|nm0000003|Brigitte Bardot|     1934|     NULL|actress,soundtrac...|tt0054452,tt00573...|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,soundtrack,...|tt0078723,tt00779...|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00509...|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_name_basics WITH 555345 ROWS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\n",
      "|  titleId|ordering|               title|region|language|      types|   attributes|isOriginalTitle|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\n",
      "|tt0000001|       1|          Карменсіта|    UA|    NULL|imdbDisplay|         NULL|              0|\n",
      "|tt0000001|       2|          Carmencita|    DE|    NULL|       NULL|literal title|              0|\n",
      "|tt0000001|       3|Carmencita - span...|    HU|    NULL|imdbDisplay|         NULL|              0|\n",
      "|tt0000001|       4|          Καρμενσίτα|    GR|    NULL|imdbDisplay|         NULL|              0|\n",
      "|tt0000001|       5|          Карменсита|    RU|    NULL|imdbDisplay|         NULL|              0|\n",
      "+---------+--------+--------------------+------+--------+-----------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_title_akas WITH 190567 ROWS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|              genres|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|          Carmencita|      0|     1894|   NULL|             1|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|Le clown et ses c...|      0|     1892|   NULL|             5|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      Pauvre Pierrot|      0|     1892|   NULL|             4|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|         Un bon bock|      0|     1892|   NULL|            12|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|    Blacksmith Scene|      0|     1893|   NULL|             1|        Comedy,Short|\n",
      "+---------+---------+--------------------+--------------------+-------+---------+-------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_title_basics WITH 7958 ROWS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+\n",
      "|   tconst|directors|writers|\n",
      "+---------+---------+-------+\n",
      "|tt0000001|nm0005690|   NULL|\n",
      "|tt0000002|nm0721526|   NULL|\n",
      "|tt0000003|nm0721526|   NULL|\n",
      "|tt0000004|nm0721526|   NULL|\n",
      "|tt0000005|nm0005690|   NULL|\n",
      "+---------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_title_crew WITH 7958 ROWS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|   tconst|ordering|   nconst|       category|                 job|characters|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|tt0000001|       1|nm1588970|           self|                NULL|  [\"Self\"]|\n",
      "|tt0000001|       2|nm0005690|       director|                NULL|      NULL|\n",
      "|tt0000001|       3|nm0374658|cinematographer|director of photo...|      NULL|\n",
      "|tt0000002|       1|nm0721526|       director|                NULL|      NULL|\n",
      "|tt0000002|       2|nm1335271|       composer|                NULL|      NULL|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_title_principals WITH 77941 ROWS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.7|    2034|\n",
      "|tt0000002|          5.7|     272|\n",
      "|tt0000003|          6.5|    1981|\n",
      "|tt0000004|          5.4|     178|\n",
      "|tt0000005|          6.2|    2739|\n",
      "+---------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATED TABLE: extra_title_ratings WITH 7958 ROWS!\n"
     ]
    }
   ],
   "source": [
    "with DuckDBContext(duckdb_database) as ctx:\n",
    "    train_ids = ctx.conn.execute(\"SELECT tconst FROM imdb_train\").fetchdf()\n",
    "    train_ids_spark = spark.createDataFrame(train_ids)\n",
    "\n",
    "    for ds in extra_imdb:\n",
    "        table_name = f\"extra.{get_table_name(ds)}\".replace(\".\", \"_\")\n",
    "\n",
    "        # Load a small subset of the data to infer the schema\n",
    "        subset = spark.read.csv(\n",
    "            f\"../../data/extra/{ds}\",\n",
    "            header=True,\n",
    "            sep=\"\\t\",\n",
    "            nullValue=\"\\\\N\",\n",
    "            inferSchema=True,\n",
    "        ).limit(1000)\n",
    "\n",
    "        # Extract the schema from the subset\n",
    "        schema = subset.schema\n",
    "\n",
    "        # Load all TSV.GZ files in the data directory into a dataframe with the inferred schema\n",
    "        spark_df = spark.read.csv(\n",
    "            f\"../../data/extra/{ds}\",\n",
    "            header=True,\n",
    "            sep=\"\\t\",\n",
    "            nullValue=\"\\\\N\",\n",
    "            schema=schema,\n",
    "        )\n",
    "        spark_df.show(5)\n",
    "\n",
    "        spark_df_columns = spark_df.columns\n",
    "\n",
    "        if \"titleId\" in spark_df_columns:\n",
    "            filtered_spark_df = spark_df.join(\n",
    "                train_ids_spark, train_ids_spark.tconst == spark_df.titleId, \"inner\"\n",
    "            )\n",
    "            filtered_spark_df = filtered_spark_df.drop(\"titleId\")\n",
    "        elif \"knownForTitles\" in spark_df_columns:\n",
    "            # Split the knownForTitles column into multiple rows\n",
    "            spark_df = spark_df.withColumn(\n",
    "                \"knownForTitles\", explode(split(spark_df[\"knownForTitles\"], \",\"))\n",
    "            )\n",
    "\n",
    "            # Select the values that are in both train_ids_spark and spark_df\n",
    "            filtered_spark_df = spark_df.join(\n",
    "                train_ids_spark,\n",
    "                spark_df.knownForTitles == train_ids_spark.tconst,\n",
    "                \"inner\",\n",
    "            )\n",
    "        elif \"tconst\" in spark_df_columns:\n",
    "            filtered_spark_df = spark_df.join(train_ids_spark, \"tconst\", \"inner\")\n",
    "\n",
    "        ctx.save_to_duckdb(filtered_spark_df, table_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
