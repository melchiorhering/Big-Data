{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using magic command you can also add Poetry packages to the Jupyter Notebook\n",
    "# !poetry add package_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl  # Faster than Pandas Dataframe library (Rust based library)\n",
    "import pandas as pd  # Goo'ol Pandas\n",
    "from pyspark.sql import SparkSession  # Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/13 15:14:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"Local PySpark Session\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+----------------+---------+-------+--------------+--------+-----+\n",
      "|_c0|   tconst|        primaryTitle|   originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|\n",
      "+---+---------+--------------------+----------------+---------+-------+--------------+--------+-----+\n",
      "| 14|tt0014109|The Saga of Gösta...|            NULL|     1924|   NULL|           183|  1231.0| True|\n",
      "| 24|tt0015064|      The Last Laugh| Der letzte Mann|     1924|   NULL|            77|    NULL| True|\n",
      "| 32|tt0015841|        The Freshman|    The Freshman|     1925|   NULL|            77|  5374.0| True|\n",
      "| 47|tt0017271|          By the Law|            NULL|     NULL|   1926|            80|  1057.0| True|\n",
      "| 56|tt0018451|The Student Princ...|            NULL|     1927|   NULL|           106|  1459.0| True|\n",
      "| 62|tt0018742|       The Cameraman|   The Cameraman|     1928|   NULL|            76| 11388.0| True|\n",
      "| 69|tt0019379|         Show People|            NULL|     1928|   NULL|            83|  3695.0| True|\n",
      "| 76|tt0020018|      In Old Arizona|            NULL|     1928|   NULL|            95|  1049.0|False|\n",
      "| 80|tt0020793|Escape from Dartmoor|            NULL|     1929|   NULL|            88|  1102.0| True|\n",
      "| 90|tt0022125|              Marius|            NULL|     1931|   NULL|           130|  2251.0| True|\n",
      "| 99|tt0022626|    American Madness|            NULL|     1932|   NULL|            75|  1996.0| True|\n",
      "|107|tt0023622| Trouble in Paradise|            NULL|     1932|   NULL|            83| 14090.0| True|\n",
      "|113|tt0023876|           Cavalcade|       Cavalcade|     NULL|   1933|           112|  5038.0|False|\n",
      "|129|tt0024593|         Son of Kong|            NULL|     1933|   NULL|            70|  4501.0|False|\n",
      "|136|tt0025164|    Thé Gáy Divớrcéé|The Gay Divorcee|     1934|   NULL|           107|    NULL| True|\n",
      "|164|tt0027532|           Dớdswớrth|            NULL|     1936|   NULL|           101|  8817.0| True|\n",
      "|169|tt0027977|        Modern Times|            NULL|     1936|   NULL|            87|231243.0| True|\n",
      "|171|tt0028070|       Our Relations|            NULL|     NULL|   1936|            71|  3077.0| True|\n",
      "|179|tt0028315|            Stớwáwáy|            NULL|     1936|   NULL|            87|  1323.0| True|\n",
      "|189|tt0028773|            Dead End|        Dead End|     1937|   NULL|            93|    NULL| True|\n",
      "+---+---------+--------------------+----------------+---------+-------+--------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/13 15:14:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \\N, tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes, label\n",
      " Schema: _c0, tconst, primaryTitle, originalTitle, startYear, endYear, runtimeMinutes, numVotes, label\n",
      "Expected: _c0 but found: \\N\n",
      "CSV file: file:///workspaces/Big-Data/data/train-4.csv\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns to keep\n",
    "columns_to_keep = [\n",
    "    \"column1\",\n",
    "    \"column2\",\n",
    "    \"column3\",\n",
    "    \"column4\",\n",
    "    \"column5\",\n",
    "    \"column6\",\n",
    "    \"column7\",\n",
    "    \"column8\",\n",
    "]\n",
    "\n",
    "# Load all CSV files in the data directory into a dataframe\n",
    "# Specify '\\\\N' as a null value\n",
    "df = spark.read.csv(\"../../data/*.csv\", header=True, nullValue=\"\\\\N\")\n",
    "\n",
    "# # Only keep the specified columns\n",
    "# df = df.select(columns_to_keep)\n",
    "\n",
    "# Print the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Polars and or Pandas\n",
    "\n",
    "A lot of Data-Wrangling is necessary because the data is dirty!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Polars you can read multiple files at once using a wildcard\n",
    "\n",
    "# Since\n",
    "# Specify the columns to keep\n",
    "columns_to_keep = [\n",
    "    \"column1\",\n",
    "    \"column2\",\n",
    "    \"column3\",\n",
    "    \"column4\",\n",
    "    \"column5\",\n",
    "    \"column6\",\n",
    "    \"column7\",\n",
    "    \"column8\",\n",
    "]\n",
    "\n",
    "# Load all CSV files in the data directory into a dataframe\n",
    "# Specify '\\\\N' as a null value and only keep the specified columns\n",
    "df = pl.read_csv(\"../../data/*.csv\", null_values=[\"\\\\N\"], with_columns=columns_to_keep)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
