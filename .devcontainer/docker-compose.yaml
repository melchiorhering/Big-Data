version: "3.8"
services:
  orchestration:
    networks:
      - default
    build:
      context: .
      dockerfile: ../src/orchestration/Dockerfile
    working_dir: /home/workspaces/BigData/orchestration/
    stdin_open: true
    tty: true
    volumes:
      #   # Update this to wherever you want VS Code to mount the folder of your project
      - ../src/orchestration:/home/workspaces/BigData/orchestration/
    # entrypoint: [./startup-script.sh]
    ports:
      - 3000:3000
  streamlit:
    networks:
      - default
    build:
      context: .
      dockerfile: ../src/streamlit/Dockerfile
    working_dir: /home/workspaces/BigData/streamlit/
    stdin_open: true
    tty: true
    volumes:
      #   # Update this to wherever you want VS Code to mount the folder of your project
      - ../src/streamlit:/home/workspaces/BigData/streamlit
      # - ../src/orchestration/db/BIGDATA.duckdb:/home/workspaces/BigData/streamlit/BIGDATA.duckdb
      # - ../src/mlflow:/home/workspaces/BigData/streamlit/mlflow
    # entrypoint: [./startup-script.sh]
    ports:
      - 8501:8501
  mlflow:
    networks:
      - default
    build:
      context: .
      dockerfile: ../src/mlflow/Dockerfile
    working_dir: /home/workspaces/BigData/mlflow
    stdin_open: true
    tty: true
    volumes:
      - ../src/mlflow:/home/workspaces/BigData/mlflow/
    # entrypoint: [./startup-script.sh]
    ports:
      - 5001:5001

  workspace:
    networks:
      - default
    build:
      context: .
      dockerfile: ../.devcontainer/docker/Dockerfile
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ..:/home/workspaces/BigData/
    working_dir: /home/workspaces/BigData/
    # command: [./startup-script.sh]
    stdin_open: true
    tty: true
    depends_on:
      - streamlit
      - orchestration
      - mlflow
networks:
  default:
    driver: bridge
  servers_default:
    external: true
